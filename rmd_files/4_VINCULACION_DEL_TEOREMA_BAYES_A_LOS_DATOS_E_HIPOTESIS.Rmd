---
output:
  pdf_document: default
  html_document: default
---

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```
El estudio de caso de Monico proporciona un ejemplo tangible de los diferentes componentes de un análisis bayesiano, incluida la estimación de la probabilidad de un evento y la probabilidad de un evento dado otro (usando los datos actualmente disponibles), junto con los conceptos clave de verosimilitud, probabilidades previas y posteriores, y cómo actualizar el conocimiento de uno utilizando el anterior bayesiano posterior como el nuevo previo. Aunque el procedimiento ejemplificado aquí es específico para los datos de conteo arqueológico, el teorema de Bayes es muy general y puede ser útil para una amplia variedad de datos y procesos de generación de datos. Esta sección generaliza el teorema de Bayes a una variedad de otros escenarios científicos.  

Anteriormente mencionamos que los científicos bayesianos utilizan los datos disponibles $(D)$ para asignar probabilidades a declaraciones o hipótesis $(H)$ sobre una población. El enunciado $P(H|D)$, es decir, la probabilidad de la hipótesis dados los datos formaliza esta relación. En nuestro ejemplo de los sitios de Monico, el arqueólogo estaba tratando de calcular la probabilidad de que la gente de Monico matara perros y coyotes (las hipótesi) dada la cantidad de marcas de corte en sus huesos (los datos disponibles). Para operacionalizar esta declaración en el contexto de datos e hipótesis, el teorema de Bayes funciona de la siguiente manera:


$$P(H|D) = \dfrac{P\left(D|H\right)\times P(H)}{P(D)}$$
donde $P(H|D)$ es la **probabilidad posterior** de la hipótesis dados los datos; $P(D|H)$ es la probabilidad de los datos dada la hipótesis (o la  **verosimilitud**) de los datos observados; $P(H)$ es la **probabilidad previa** de la hipótesis (antes de que se recopilaran los datos); y $P(D)$ es la probabilidad de los datos disponibles (de todos los valores posibles de los datos). Alternativamente, generalizando y utilizando un vernáculo estadístico más moderno, esta operación puede expresarse como:

$$\text{Posterior} = \dfrac{\text{verosimilitud}\times\text{previa}}{P(\text{datos})}$$

De esta manera, la estadística bayesiana ofrece un marco estadístico alternativo para actualizar y evaluar hipótesis a través de un mecanismo que obtiene información *a posteriori* sobre el posterior de interés a partir de los datos, un modelo estadístico (expresado como verosimilitud), e información previa adecuadamente formulada. En otras palabras, con una declaración explícita de nuestra información previa, un modelo estadístico claramente definido y el deseo de actualizar nuestra comprensión, el teorema de Bayes nos brinda un marco probabilístico para hacer interpretaciones.

Además de la naturaleza coherente y explícita del marco, hay otra característica atractiva del paradigma bayesiano, a saber, que nos permite aprender de la experiencia. Los antecedentes permiten la contextualización explícita de conocimientos o creencias previas sobre el tema que se investiga [@buck_bayesian_1996;@cowgill_distinguished_1993]. El uso de conocimientos previos debería ser una tendencia natural para los arqueólogos. Como Buck, et al. [-@buck_bayesian_1996] los arqueólogos aplican conocimientos previos a menudo, por ejemplo, al inferir la función de artefactos recién descubiertos mediante su asociación con artefactos y características que ya se han descubierto. De manera similar, el arqueólogo de nuestro ejemplo pudo contextualizar los datos del sitio Monico-2 basándose en las observaciones de Monico-1. Pocos otros marcos interpretativos ofrecen una estructura clara para actualizar las creencias a la luz de la nueva información y, sin embargo, esta es una parte tan importante de la mayoría de los enfoques intuitivos para aprender sobre el mundo en el que vivimos. Además, la información posterior de hoy (basada en datos actuales e información previa) está en una forma adecuada para convertirse en información previa para trabajos futuros si y cuando haya más datos disponibles. 

### Desde inferencias sobre puntos discretos hasta distribuciones de datos

Hasta ahora, el ejemplo ha mostrado cómo se puede aplicar la inferencia bayesiana a hipótesis definidas por declaraciones sobre eventos discretos. En el ejemplo ficticio anterior, las hipótesis estaban representadas por afirmaciones sobre si los restos de fauna observados eran el resultado de una matanza. Los datos observados asignaron probabilidades a cada hipótesis, indicando así la cantidad o grado de creencia en la hipótesis. Estos datos fueron eventos discretos de solamente dos sitios. Sin embargo, en realidad, aunque la población de la proporción de huesos de perro sacrificados son los resultados del mismo proceso de comportamiento (matanza), es probable que estos valores varíen de un sitio a otro.

En consecuencia, muchos arqueólogos podrían desear comparar sus datos de un solo sitio con el universo de sitios conocidos. En este caso, las hipótesis a evaluar se caracterizan por los valores de los **parámetros** of a probability model. Although we mentioned this earlier, at this point de un modelo de probabilidad. Si bien lo mencionamos anteriormente, en este punto vale la pena recordar que tales parámetros describen ciertas características de una muestra o población. Para los arqueólogos, los parámetros más comunes son los que miden la tendencia central, como la media o la mediana. La inferencia bayesiana se puede realizar utilizando otros parámetros, así como la distribución completa de la información posterior, previa y de datos. Estos suelen estar representados por modelos de probabilidad. Probablemente, el modelo de este tipo más conocido es el modelo de probabilidad normal, en el que la distribución de probabilidad tiene una forma de campana simétrica alrededor de un único valor medio. Cuando se trata de datos (de muestra) y modelos asociados de probabilidad, es convencional utilizar el símbolo romano $x$ para representar los datos observados (o de muestra) y el símbolo griego $\theta$ *(theta)* para representar el parámetro (o conjunto múltiple de parámetros) del modelo de población que estamos tratando de conocer. Dado $x$ y un modelo con parámetro(s) $\theta$, podemos volver a formular el teorema de Bayes y sus tres componentes (la *verosimilitud*, la *previa*, y la *posterior*) en el contexto de las distribuciones de datos y sus modelos de probabilidad.

La *verosimilitud* es una función estadística, o una expresión matemática, que asocia cantidades de datos individuales con sus respectivos valores de probabilidad. Su forma está determinada por el modelo de probabilidad específico que se utiliza, pero, en términos generales, está representada por $P(x|\theta)$, es decir, la distribución de probabilidad de los datos recién observados condicionados por los parámetros. En consecuencia, la verosimilitud es la probabilidad de observar valores de datos particulares dados algunos valores específicos (o hipotéticos) de los parámetros desconocidos. Por lo tanto, esta es una declaración formal de la relación entre los parámetros sobre los que queremos aprender y los datos que recopilamos.

La *previa* itambién es una función y puede representarse por $P(\theta)$. Es una declaración de lo que sabemos sobre la distribución de probabilidad de los parámetros antes de que se recolecten nuevos datos. En términos simples, podemos pensar en esto como la probabilidad que asignamos a la observación de valores específicos de los parámetros desconocidos en función de lo que sabíamos antes de observar los datos. Esta es una declaración formal de nuestro conocimiento antes de recopilar los datos más recientes.

La *posterior* es lo que queremos obtener: una combinación de la información contenida en los nuevos datos, la verosimilitud y la previa. El posterior está representado por $P(\theta|x)$. Como se presentó en la sección anterior, esta es la probabilidad de la hipótesis dados los datos, o $P(H|D)$. Es la distribución de probabilidad de los parámetros del modelo condicionados a los datos. En términos simples, podemos pensar en esto como la probabilidad que asignamos a valores específicos o hipotéticos de los parámetros desconocidos después de observar nuevos datos. En este contexto, podemos expresar el teorema de Bayes como:

$$P(\theta|x) = \dfrac{P\left(x|\theta\right)\times P(\theta)}{P(x)}$$

### El arqueólogo bayesiano y la incertidumbre de la hipótesis

Como se describió anteriormente, la inferencia bayesiana sobre Monico-2 proporcionada al reportero se basó únicamente en los nuevos datos de Monico-2 y la experiencia previa del experto arqueólogo con Monico-1. Sin embargo, si el arqueólogo quiere darle al reportero la mejor estimación posible, podría usar toda la evidencia disponible, incluidos los datos de Monico-2, su conocimiento experto e información de otros sitios arqueológicos. Para hacer esto, el arqueólogo revisa la literatura publicada e identifica información adicional sobre la proporción de perros con marcas de matanza recuperados de 38 sitios de Monico previamente excavados. Posteriormente, el arqueólogo busca investigar la variabilidad del comportamiento de matanza de perros como lo demuestra la proporción de perros con marcas de matanza en cada sitio de Monico, con miras a obtener una declaración previa probabilística sobre el parámetro theta, $\theta$ (la proporción de perros con marcas de matanza).

La Tabla 5 ilustra la distribución de los valores de $\theta$ a través de la frecuencia y proporciones de los sitios. La tabla muestra que, de los 38 sitios, 20 informaron tener entre 0 % y 5 % de perros que mostraban evidencia de marcas de matanza. Doce sitios tienen entre 6 % y 15 % de perros que muestran evidencia de marcas de matanza, mientras que otros cuatro sitios reportan valores de $\theta$ entre 16 % y 35 %. Mientras tanto, otros dos sitios arqueológicos reportan que $\theta$ oscila entre 36 % y 75 %. No hay sitios con más del 75 % de restos de perros que muestren evidencia de matanza.

```{r echo = FALSE, eval=TRUE}
p = c(seq(0.05, 0.95, by = 0.1), 1); 
# number of sites with these proportions from the literature
prior_n <- c(20, 12, 3, 1, 1, 0, 0, 1, 0, 0, 0)
# prior probabilities of each p proportion
prior_d = prior_n / sum(prior_n);
p_labels <- sapply(2:(length(c(0, p))), function(x) paste(c(0, p)[x - 1], c(0, p)[x], sep = "-"))
kb <- kable(dplyr::tibble(p_label = p_labels, n = prior_n, d = prior_d), digits = 2,
          col.names = c("Proporción de restos de perros con marcas de matanza ($\\theta$)",
                        "Número de sitios con ($\\theta$) reportado",
                        "Proporción del número total de sitios con ($\\theta$) reportado (probabilidad previa)"),
          caption = "Distribución de frecuencias del número de sitios con proporciones informadas de restos de perros con marcas de matanza ($\\theta$) y la proporción del número total de sitios con marcas de matanza en huesos de perros (probabilidades previas)", escape = FALSE)
kableExtra::kable_styling(kb, bootstrap_options = "hover", full_width = F)
```

Para empezar, el arqueólogo habla con otros expertos sobre nutrición, arqueología de los alimentos y arqueología y etnografía de Monico. Con base en su conocimiento científico, plantean la hipótesis de que, para considerar que los perros han hecho una contribución alimentaria sustancial en un sitio de Monico, debería haber evidencia de marcas de matanza en al menos el 50 % de los perros individuales. «Entonces», piensa el arqueólogo, «mi primera hipótesis, *H~1~*, es que el valor de θ debería ser al menos del 50 %, o 0.5, para cualquier sitio específico de Monico. ¿Cuál es la probabilidad de que esta hipótesis sea correcta para Monico-2 según los datos que tengo y mi conocimiento previo?».

La muestra del sitio Monico-2 indicó que, de 10 perros individuales, 9 tenían marcas de matanza (por lo tanto, $\theta$ = 0.9). El arqueólogo quiere usar el conocimiento previo, incluida la información de la revisión de la literatura, para comprender la variabilidad de $\theta$ en los sitios de la aldea de Monico.

El arqueólogo primero registra las proporciones de matanza de perros ($\theta$), de los 38 sitios encontrados en la literatura. Para resumir estos datos, en la Tabla 5 (columna 1), agrupan los valores de $\theta$ en intervalos iguales en incrementos de 0.10 (10 %, excepto el primer intervalo, que es menor). También registran el número de sitios que reportan valores de $\theta$ en cada intervalo (columna 2). Luego, el arqueólogo calcula la probabilidad previa de cada intervalo $\theta$ dividiendo el número en cada celda de la columna 2 de la Tabla 5 por el número total de sitios, es decir, 38. De esta forma, la tercera columna de la Tabla 5 reporta la proporción de sitios dentro de cada intervalo $\theta$. Esta distribución de frecuencia también sirve como distribución previa de los valores de $\theta$.

```{r, include=FALSE, message=FALSE, warning=FALSE}
# packages ----------------------------------------------------------------

library(dplyr)
library(ggplot2)
library(tidyr)
library(ggrepel)
library(ggtext)
```
```{r, echo=FALSE}
# new ggplot theme ---------------------------------------------------------
ggplot2::theme_set(
  ggplot2::theme_classic()+
    ggplot2::theme(
      plot.margin = unit(c(.2,.2,.2,.2), "in"),
      plot.background = element_rect(fill = "#f5f5f5"),
      panel.background = element_rect(fill = NA),
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      panel.grid.major.y = element_line(color = "#d2d2d2"),
      panel.grid.minor.y = element_line(color = "#d2d2d250"),
      axis.title = element_text(face = "bold", size = 12),
      axis.text = element_text(size = 10),
      axis.line = element_line()
    ))
```


```{r prior-plot, eval=TRUE, include=FALSE}
data <- data.frame(p, p_labels, prior_d,prior_n) %>%
  add_row(p = 0.05, prior_d = seq(0,0.53, 0.001)) %>% 
  add_row(p = 0.15, prior_d = seq(0,0.32, 0.001)) %>% 
  add_row(p = 0.25, prior_d = seq(0,0.08, 0.001)) %>% 
  add_row(p = 0.35, prior_d = seq(0,0.03, 0.001)) %>% 
  add_row(p = 0.45, prior_d = seq(0,0.03, 0.001)) %>% 
  add_row(p = 0.75, prior_d = seq(0,0.03, 0.001)) %>% 
  mutate(p = as.numeric(as.character(p))) %>% 
  mutate(label_place = case_when(p == 0.05 ~ 0.025,
                                 p == 0.15 ~ 0.1,
                                 p == 0.25 ~ 0.2,
                                 p == 0.35 ~ 0.3,
                                 p == 0.45 ~ 0.4,
                                 p == 0.75 ~ 0.7
                                 )) %>% 
  mutate(new_p = p-0.01) %>% 
  mutate(bar_prior_d = 0.001) %>% 
  filter(is.na(prior_n) | (new_p < 0 | new_p > 1))


data3 <- data.frame(p, p_labels, prior_d,prior_n) %>%
  mutate(p = as.numeric(p)) %>% 
  mutate(x_inf = lag(p),
         x_sup = p) 

d<-data %>% 
  ggplot(aes(x = new_p, y = bar_prior_d, fill = prior_d, color = prior_d))+
  geom_bar(stat = "identity")+
  geom_text(data = data %>% 
              group_by(p) %>% 
              filter(prior_d == max(prior_d)),
            aes(x = new_p,
                y = prior_d,
                label = ifelse(prior_d != 0,round(prior_d, 4), NA)),
            color = "black",
            vjust = -0.4,
            hjust = 0.5)+
  #geom_point(x = 1, y = 0.6, color = NA)+
  scale_y_continuous(expand = expansion(mult = c(0, .01)), 
                     limits = c(0.001,0.6),
                     breaks = seq(0,1,0.1))+
  scale_x_binned(breaks = c(0,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,1),
                 labels = c(0,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,1),
                 expand = c(0,0),
                 limits = c(0,1)
  )+
  scale_fill_gradient(low="#ffd82b", high="#F3010A")+ #red
  scale_color_gradient(low="#ffd82b", high="#F3010A")+ #red
  
  labs(
    x = paste("Proportion of Dogs with Butchery Marks at Monico Archaeological Sites (*\u03B8*)"),
    y = paste("Prior Probability, P(*\u03B8*)")
  )+
  theme(
    axis.ticks.x = element_line(),
    legend.position = "none",
    #plot.background = element_rect(fill = "#242424", color = NA),
    #text = element_text(color = "white"),
    #axis.text = element_text(color = "white"),
    #axis.line = element_line(color = "white"),
    #axis.ticks = element_line(color = "white"),
  )+
  coord_cartesian(xlim = c(-0.005,1)) + theme(axis.title.x = element_markdown(), axis.title.y = element_markdown())

ggsave(filename = "../output/figures/figure3.png", plot = d, width = 8, height = 5, units = 'in', dpi = 400)
```

Luego, el arqueólogo traza la distribución de la proporción de perros sacrificados en los sitios de Monico (Tabla 5) para visualizar el conocimiento previo resultante que se puede derivar de este conjunto de datos (Figura 1).

```{r fig3, echo=FALSE, message=FALSE, warning=FALSE, fig.align = "center",out.width= "\\textwidth", fig.cap=". Representación simple de la distribución de las probabilidades previas del arqueólogo de las estimaciones de $\\theta$ (theta), la proporción de perros con marcas de matanza en los sitios arqueológicos de Monico (de la Tabla 5). Tenga en cuenta que los valores pequeños de $\theta$ tienen una probabilidad previa más alta que los más grandes.", fig.pos="H"}
knitr::include_graphics("./output/figures/figure3.png")
```

Recuerde que, en el marco bayesiano, se necesita la verosimilitud ($P(x|\theta)$), la probabilidad de los datos ($P(x)$), y la probabilidad previa de la hipótesis ($P(\theta)$) para calcular la probabilidad posterior probabilidad de la hipótesis de que $\theta$ > 0.50, dados los datos ($P(\theta > 0.5|x)$). La Figura 1 ilustra la probabilidad previa, $P(\theta)$, para diferentes valores de $\theta$.

Tenga en cuenta que, en contraste con los valores de un solo evento en los ejemplos anteriores, los componentes del teorema de Bayes en este caso son distribuciones de valores. La aplicación de estadísticas bayesianas en tales situaciones brinda una ventaja particular porque el marco permite a los arqueólogos evaluar la probabilidad de una hipótesis y la incertidumbre asociada. Por lo tanto, para continuar con el análisis bayesiano de los datos de Monico-2 a la luz del conocimiento previo de los 38 sitios (representados en la Figura 1), el arqueólogo necesita un modelo para representar la probabilidad de los datos, $x$, y parámetro(s) asociados, $\theta$, para calcular la probabilidad, $P(x|\theta)$, y la probabilidad de los datos, $P(x)$.

### La verosimilitud

Para calcular la probabilidad de los datos de Monico-2 dada la hipótesis, el arqueólogo necesita una función que pueda representar la verosimilitud, $P(x|\theta)$, de estos datos, $x$, dado el parámetro de interés, $\theta$. Los arqueólogos emplean con frecuencia una función de probabilidad denominada modelo binomial para calcular la verosimilitud de datos compuestos por observaciones binarias, es decir, observaciones expresadas como 1/0, sí/no, verdadero/falso o presente/ausente. En este caso, el modelo binomial es apropiado para las observaciones que indican la presencia o ausencia de marcas de matanza en esqueletos de perros individuales, como en los datos de Monico-2. Como tal, el arqueólogo quiere calcular la verosimilitud de que 9 de cada 10 esqueletos de perros de este sitio exhiban marcas de matanza.

Matemáticamente, el modelo binomial se expresa por:


$$P(x|\theta) = {N\choose k}\times\theta^k \times (1 - \theta)^{N-k}$$

Los símbolos $k$ y $N$ representan los datos: $k$ es el número de perros observados con marcas de matanza, mientras que $N$ es el total de perros observados. El paramétro del modelo, $\theta$, en este ejemplo representa la proporción de perros con marcas de matanza de todos los perros observados en Monico- 2.  

El arqueólogo utiliza el método de estimación de parámetros llamado *máxima verosimilitud* (ML por sus siglas en inglés) para determinar el valor más probable de $\theta$ que habría generado los datos. La máxima verosimilitud pregunta, bajo el modelo binomial, ¿qué valor de $\theta$ es más probable que conduzca a los datos observados? En este caso, los datos binomiales del arqueólogo son $k = 9$ perros con marcas de matanza y $N = 10$ perros en total. La máxima verosimilitud evalúa qué valor del parámetro $\theta$ maximiza $P(x | \theta)$, la verosimilitud, en un rango sistemático de cantidades entre 0 y 1.

Para estimar el valor más probable de $\theta$, el arqueólogo supone que la probabilidad de observar cada perro sacrificado es independiente de los demás, haciendo que la probabilidad de observar 9 perros sacrificados sea $\theta^{9}$. Por el contrario, la probabilidad de observar un solo perro sin sacrificar es $(1 -\theta)^{(10-9)}$, y la probabilidad de que haya 9 perros sin sacrificar y 1 perro sin sacrificar es $\theta^9 \times (1-\theta)^{(10-9)}$. Sin embargo, para calcular la verosimilitud de los datos, el arqueólogo también debe tener en cuenta el número de formas diferentes en que las 9 observaciones de perros con marcas de matanza, $k$, pueden ocurrir en la secuencia de 10 observaciones de perros, $N$.

El modelo binomial hace esto calculando ${N\choose k}$, conocido como el *coeficiente binomial* (léase como «*N elige k*»). En este caso, si las identificaciones positivas de marcas de matanza en perros están representadas por 1 y las marcas de matanza no son 0, el coeficiente binomial calcula cuántos conjuntos desordenados podrían haber resultado en nueve 1 y un 0: por ejemplo $x = \{0, 1, 1, 1, 1, 1, 1 ,1, 1, 1\}$, $\{1, 1, 1, 1, 0, 1, 1, 1, 1, 1\}$, $\{1, 1, 1, 1, 0, 1, 1, 1, 1, 1\}$, or $\{1, 1, 1, 1, 1, 1, 1 ,1, 1, 0\}$^[No se enumeran todos los conjuntos aquí, pero este ejemplo debería permitir al lector imaginar cómo puede ocurrir esto en un total de 10 maneras únicas. Aunque en este caso la solución es bastante simple, en otras aplicaciones, la solución podría no ser tan obvia, por ejemplo, el número de formas en que pueden ocurrir cinco éxitos en 10 intentos, es decir, ${10 \eligen 5} = 252.$], ... etc. El coeficiente binomial es abreviado y puede calcularse usando la siguiente ecuación:

$${N\choose k} = \dfrac{N!}{k!\times (N - k)!}$$

donde $!$ es la función factorial que produce el producto de un número entero y todos los números enteros debajo de él. En nuestro caso, $N=10$ y $k=9$, así que: 

$$N! = 10 \times 9 \times 8\times 7 \times 6\times 5 \times 4\times 3 \times 2\times 1 = 3628800$$
$$k! = 9 \times 8 \times 7 \times 6 \times 5 \times 4 \times 3 \times 2 \times 1 = 362880$$

y  $(N - k)! = (10 - 9)! = 1! = 1$.

Por lo tanto,

$$ {N\choose k} = \dfrac{N!} {k! \times (N - k)!} = \dfrac {10!} {9! \times (10 - 9)!} = \dfrac {3,628,800} {362,880 \times 1} = 10.$$

Una vez que se ha calculado ${N\choose k}$ el arqueólogo puede continuar estimando el valor de verosimilitud de una cantidad dada de $\theta$ calculando:

$$P(N, k | \theta) = 10 \times \theta^9 \times (1 - \theta)^{(10 - 9)}$$

en el rango de valores $\theta$ de 0 a 1 para encontrar la distribución de verosimilitud de los datos y, por lo tanto, el valor de $\theta$ que maximiza la función de verosimilitud. Este planteamiento se ilustra en la Figura 2, de la cual el arqueólogo aprende que la estimación de ML de $\theta$ (dados los datos de Monico-2) es 0.9; en otras palabras, las observaciones en Monico-2 son más probables si la proporción de perros sacrificados en Monico-2 ($\theta$) también es 0.9 (or 90%).

```{r eval=TRUE, include=FALSE}


data <- c(9, 10); 

# likelihood plot
theta_values <- seq(.001, 1, length.out = 1000)#p
likelihood_k <- data[1]
likelihood_N <- data[2]
likelihoods <- dbinom(likelihood_k, likelihood_N, prob = theta_values)


data_plot4 <- data.frame(theta_values, likelihood_k, likelihood_N, likelihoods)

data_plot4 %>% 
  ggplot(aes(x = theta_values, y = likelihoods))+
  geom_ribbon(aes(ymin = 0, ymax = likelihoods), fill = "#27999A", alpha = 0.6)+
  geom_segment(aes(x = 0.9, xend = 0.9, y = 0, yend = 0.387420489), linetype = "dashed",
               size = 1)+
  geom_line(size = 1.5, color = "#27999A")+
  scale_x_continuous(breaks = seq(0,1,0.1),
                     expand = c(0,0.01))+
  scale_y_continuous(expand = expansion(mult = c(0, .01)),
                     limits = c(0,0.4),
                     breaks = seq(0,0.4,0.1))+
  labs(
    title = paste("Likelihood Distribution of *\u03B8*"),
    x = paste("Proportion of Dogs with Butchery Marks at Monico Archaeological Sites (*\u03B8*)"),
    y = paste("Likelihood,  P(x|*\u03B8*)")
  )+
  theme(
    plot.title = element_text(hjust = 0.5, size = 20)
  )+
  coord_cartesian(xlim = c(0,1)) + theme(plot.title = element_markdown(), axis.title.x = element_markdown(), axis.title.y = element_markdown())

ggsave(filename = "../output/figures/figure4.png",  width = 8, height = 5, units = 'in', dpi = 400)
```

```{r fig4, echo=FALSE, message=FALSE, warning=FALSE, fig.align = "center",out.width= "\\textwidth", fig.cap="Distribución de valores de verosimilitud estandarizados correspondientes a cantidades variables de $\\theta$ (theta) en el rango 0, 1. La línea negra discontinua indica el valor de $\\theta$ que maximiza la verosimilitud de los datos. Esto es conocido como la estimación ML de $\\theta$" , fig.pos="H"}

knitr::include_graphics("./output/figures/figure4.png")
```
^[Cabe señalar aquí que, si bien la verosimilitud genera valores en la escala de 0 a 1, no es necesariamente una función de probabilidad que suma (integra) a 1. Para trazar la verosimilitud en la misma escala que las distribuciones previa y posterior, todas las distribuciones se han normalizado (reescalado) para que sumen 1.]

### La previa

Al igual que utilizar el modelo de probabilidad binomial para obtener la distribución de verosimilitud de los datos de Monico-2, el arqueólogo puede usar otro modelo de probabilidad para expresar $P(\theta)$, la distribución de probabilidad de $\theta$, también conocida como previa. En este caso, el arqueólogo necesita una función de probabilidad que modele la distribución de $\theta$, la proporción de perros con marcas de matanza, en los 38 sitios observados antes de la excavación de Monico-2. Los estadísticos usan con frecuencia la función de probabilidad beta para modelar la distribución de proporciones como $\theta$. La expresión matemática del modelo beta es:

$$ P(H) = P(\theta) = \theta^{a - 1}\times (1 - \theta)^{b-1}$$

Por lo tanto, la forma del modelo beta está controlada por dos parámetros, $a$ y $b$, que a su vez controlan las estadísticas de resumen clave, como la media y la varianza del modelo. A diferencia del modelo de verosimilitud, el arqueólogo en este caso quiere encontrar una distribución de $\theta$ que describa cuantitativamente su conocimiento previo. Para hacer esto, los parámetros beta pueden acomodarse para que se ajusten a la forma de la distribución de datos previa en la Figura 1. A través de un mejor ajuste visual, el arqueólogo estima que los valores $a = 1.5$ y $b = 16$ dan como resultado una distribución de probabilidad que se asemeja a la del conocimiento previo sobre $\theta$ (es decir, la forma que se muestra en la Figura 1). Así, la distribución de la probabilidad, 

$$ P(H) = P(\theta) = \theta^{(1.5 - 1)}\times (1 - \theta)^{(16 - 1)}$$

en todos los valores de $\theta$ entre 0 y 1 se ilustra en la Figura 3.

```{r eval=TRUE, include=FALSE}
prior.par <- c(1.5, 16)
x <- seq(.0001, .99999, length.out = 100)

data_plot5 <- data.frame(prior.par, x) %>% 
  mutate(d_beta = dbeta(x, prior.par[1], prior.par[2]) * (0.6 / max(dbeta(x, prior.par[1], prior.par[2])))) %>% 
  add_row(x = 0, d_beta = 0)

data3[is.na(data3)] <- 0

data_plot5 %>% 
  ggplot()+
  geom_ribbon(aes(x = x, y = d_beta, ymin = 0, ymax = d_beta), fill = "#e04a3a", alpha = 0.6)+
  geom_line(aes(x = x, y = d_beta),
            size = 1.5,
            color = "#e04a3a")+
  geom_rect(data = data3, aes(xmin = x_inf, xmax = x_sup,ymin = 0, ymax = prior_d),
            #fill = "#A0F900",
            #color = "#5C8F00",
            fill = "#fad22a",
            color = "#FFCD28",
            alpha = 0.5)+
  geom_point(x = -0.1, y = 0.6, color = NA, stat = "unique")+
  scale_y_continuous(expand = expansion(mult = c(0, .01)), 
                     #limits = c(0.001,0.6),
                     breaks = seq(0,1,0.1))+
  scale_x_continuous(breaks = c(0,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,1),
                     labels = c(0,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,1),
                 expand = c(0,0),
                 limits = c(-0.1,1)
  )+
  labs(
    x = paste("Proportion of Dogs with Butchery Marks at Monico Archaeological Sites (*\u03B8*)"),
    y = paste("Prior, P(*\u03B8*)")
  )+
  theme(
    axis.ticks = element_line()
  )+
  coord_cartesian(xlim = c(-0.005,1)) + theme(axis.title.x = element_markdown(), axis.title.y = element_markdown())

ggsave(filename = "../output/figures/figure5.png",  width = 8, height = 5, units = 'in', dpi = 400)
```

```{r fig5, echo=FALSE, message=FALSE, warning=FALSE, fig.align = "center",out.width= "\\textwidth", fig.cap="Modelo de probabilidad beta estandarizado, con parámetros $a$ = 1.5, y $b$ = 16, que representan las probabilidades previas del arqueólogo representadas en la Figura 3. Tenga en cuenta la similitud con la Figura 3 en términos de forma y, en particular, la ubicación de la moda y el rango de valores.", fig.pos="H"}
knitr::include_graphics("./output/figures/figure5.png")
```

### La posterior

El arqueólogo es consciente de que los estadísticos utilizan con frecuencia las distribuciones binomial y beta en el contexto de los análisis bayesianos porque funcionan bien juntas para modelar las distribuciones de verosimilitud y de probabilidad previa, respectivamente, lo que simplifica los cálculos necesarios para calcular la posterior. Tales pares convenientes de modelos de probabilidad se conocen como *conjugadas*. Como resultado de las elecciones de modelado realizadas, el arqueólogo puede combinar algebraicamente los datos de verosimilitud binomial con los parámetros de la distribución beta previa para producir una distribución beta posterior representada por:

$$P(H|D) = P(\theta|x) = \theta ^ {(k_{verosimilitud} + a_{previa} - 1)} \times (1 - \theta) ^ {(N_{verosimilitud} - k_{verosimilitud} + b_{previa} - 1)}$$

$$P(\theta|x) = \theta ^ {(9 + 1.5 - 1)} \times (1 - \theta) ^ {(10 - 0 + 16 - 1)}$$

Por lo tanto, generan valores de $P(x|\theta)$, la verosimilitud y  $P(\theta)$, las probabilidades previas, para calcular $P(\theta|x)$, la distribución de probabilidad posterior, a través de una cuadrícula fina de $\theta$ en el intervalo 0, 1 (1,000 valores entre 0 y 1). Estos están ilustrados en la Figura 4. 

```{r include=FALSE, eval=TRUE}
# using a finer grid of 1,000 theta values
# from 0, to 1.
theta_values = seq(0, 1, length = 1000)
prior_a = prior.par[1]
prior_b = prior.par[2]
likelihood_k = data[1] #number of dogs observed with butchery marks
likelihood_N = data[2] #total number of dogs observed

prior_probabilities = dbeta(theta_values, prior_a, prior_b) / 21
likelihoods = dbeta(theta_values, likelihood_k + 1, likelihood_N - likelihood_k + 1) / 21
posterior_probabilities = dbeta(theta_values, likelihood_k + prior_a, likelihood_N - likelihood_k + prior_b) / 21

data_plot6 <- data.frame(theta_values, posterior_probabilities, likelihoods, prior_probabilities)
text_position <- data_plot6 %>%
  pivot_longer(
    cols = c(2:4)
  ) %>% 
  mutate(theta_values = round(theta_values,3))

data_plot6 %>% 
  ggplot(aes(x = theta_values))+
  #left
  geom_ribbon(aes(ymin = 0, ymax = prior_probabilities), fill = "#e04a3a", alpha = 0.6)+
  geom_line(aes(y = prior_probabilities, color = "Prior"), size = 1.5)+
  geom_text_repel(data = text_position,
                  aes(x = theta_values, y = value,
                      fontface = "bold",
                      segment.size = 0.8,
                      label = ifelse(theta_values == 0.101 & name == "prior_probabilities", "Prior", "")),
                  force = 30,
                  nudge_y = 0.06,
                  min.segment.length = 0,
                  max.overlaps = Inf,
                  segment.curvature = -0.1,
                  segment.ncp = 3,
                  segment.angle = 20,
                  color = "#e04a3a")+
  #center
  geom_ribbon(aes(ymin = 0, ymax = posterior_probabilities), fill = "#6a279a", alpha = 0.6)+
  geom_line(aes(y = posterior_probabilities, color = "Posterior"), size = 1.5)+
  geom_text_repel(data = text_position,
                  aes(x = theta_values, y = value,
                      fontface = "bold",
                      segment.size = 0.8,
                      label = ifelse(theta_values == 0.401 & name == "posterior_probabilities", "Posterior", "")),
                  force = 30,
                  nudge_y = 0.05,
                  nudge_x = 0.05,
                  min.segment.length = 0,
                  max.overlaps = Inf,
                  segment.curvature = -0.1,
                  segment.ncp = 3,
                  segment.angle = 20,
                  color = "#6a279a")+
  #right
  geom_ribbon(aes(ymin = 0, ymax = likelihoods), fill = "#27999A", alpha = 0.6, size = 1)+
  geom_line(aes(y = likelihoods, color = "Likelihood"), size = 1.5)+
  geom_text_repel(data = text_position,
                  aes(x = theta_values, y = value,
                      fontface = "bold",
                      segment.size = 0.8,
                      label = ifelse(theta_values == 0.850 & name == "likelihoods", "Likelihood", "")),
                  force = 30,
                  nudge_y = 0.08,
                  nudge_x = -.1,
                  min.segment.length = 0,
                  max.overlaps = Inf,
                  segment.curvature = 0.1,
                  segment.ncp = 3,
                  segment.angle = 20,
                  color = "#27999A")+
  scale_color_manual(values = c("Prior" = "#e04a3a",
                                "Posterior" = "#6a279a",
                                "Likelihood" = "#27999A"))+
  scale_y_continuous(expand = expansion(mult = c(0, .01)),
                     breaks = seq(0,1,0.1),
                     limits = c(0,0.4))+
  scale_x_continuous(breaks = seq(0,1,0.1),
                     expand = c(0,0.01))+
  labs(
    x = paste("Proportion of Dogs with Butchery Marks at Monico Archaeological Sites (*\u03B8*)"),
    y = paste("Probability Density")
  )+
  theme(
    legend.position = "none"
  ) + theme(axis.title.x = element_markdown(), axis.title.y = element_markdown())

ggsave(filename = "../output/figures/figure6.png",  width = 8, height = 5, units = 'in', dpi = 400)
```

```{r fig6, echo=FALSE, message=FALSE, warning=FALSE,fig.align = "center", out.width= "\\textwidth", fig.cap="Distribuciones de las probabilidades previas del arqueólogo, la verosimilitud de los datos y las probabilidades posteriores. Todas las densidades de probabilidad están estandarizadas por una constante de normalización.", fig.pos="H"}
knitr::include_graphics("./output/figures/figure6.png")
```


Después, el arqueólogo se centra en $P(\theta|x)$, la distribución posterior. El posterior les ayudará a hacer inferencias sobre la probabilidad de $\theta$ y su incertidumbre asociada (Figura 4). El arqueólogo puede representar visualmente la estimación de $\theta$ (la proporción esperada de perros con marcas de matanza en Monico-2, según los datos observados y el conocimiento previo de los otros 38 sitios arqueológicos de Monico) y el rango de incertidumbre del 90 % de su estimación con un gráfico en la Figura 5. 

```{r include=FALSE, eval=TRUE}
#library(HDInterval)
#If we want to use HDI instead of quantiles
# identify range of highest density interval
#First, simulate a large number of draws from the posterior distribution
set.seed(456)
posterior_samples <- rbeta(1e5, likelihood_k + prior_a, likelihood_N - likelihood_k + prior_b)
# 90% highest (posterior) density interval
posterior_hdi_90 <- round(HDInterval::hdi(posterior_samples, credMass = 0.90), 2) #0.23, 0.53

# center value of theta (posterior median)
posterior_median <- qbeta(p = 0.50,
           likelihood_k + prior_a,
           likelihood_N - likelihood_k + prior_b,
           lower.tail = TRUE)

#Hypothesis: what is probability of 0.5 and greater?
hypothesis_1_over50 <- pbeta(q = 0.50,
                             likelihood_k + prior_a,
                             likelihood_N - likelihood_k + prior_b,
                             lower.tail = FALSE)

data_plot7 <- data.frame(theta_values, posterior_probabilities) %>% 
  mutate(shade = theta_values > posterior_hdi_90[1] & theta_values < posterior_hdi_90[2])


data_plot7 %>% 
  ggplot(aes(x = theta_values, y = posterior_probabilities))+
  geom_ribbon(aes(ymin = 0, ymax =posterior_probabilities,  fill = shade))+
  #h
  geom_segment(x = posterior_hdi_90[1], y = 0.04, xend = posterior_hdi_90[2], yend = 0.04)+
  annotate("text", x = posterior_median, y = 0.02, size = 5,
           label = paste("|—  90% probabillity range  —|"))+
  #v
  geom_segment(x = posterior_median, y = 0.04, xend = posterior_median, yend = max(posterior_probabilities),
               linetype = "dashed")+
  annotate("text", x = 0.36, y = 0.11, size = 5, label = "50th-percentile", angle = 90)+
  geom_line(size = 1.5, color = "#6a279a")+
  scale_fill_manual(values = c("TRUE" = "#6a279a40",
                               "FALSE" = "#6a279a00"))+
  scale_y_continuous(expand = expansion(mult = c(0, .01)),
                     breaks = seq(0,0.2,0.05))+
  scale_x_continuous(breaks = seq(0,1,0.1),
                     expand = c(0,0.01))+
  labs(
    x = paste("Proportion of Dogs with Butchery Marks at Monico Archaeological Sites (*\u03B8*)"),
    y = paste("Posterior,  P(*\u03B8*|x)")
  )+
  theme(
    legend.position = "none"
  )+
  coord_cartesian(xlim = c(0,0.76)) + theme(axis.title.x = element_markdown(), axis.title.y = element_markdown())

ggsave(filename = "../output/figures/figure7.png",  width = 8, height = 5, units = 'in', dpi = 400)
```


```{r fig7, echo=FALSE, message=FALSE, warning=FALSE, fig.align = "center",out.width= "\\textwidth",fig.cap=". Distribución de probabilidad posterior con la línea punteada azul que muestra la estimación mediana (percentil 50) $(0.38)$. La línea negra sólida representael intervalo de densidad de probabilidad del 90\\% $(0.23--0.53)$.", fig.pos="H"}
knitr::include_graphics("./output/figures/figure7.png")
```

A diferencia del marco NHST, la probabilidad posterior bayesiana permite al arqueólogo asignar probabilidades a las hipótesis sobre los valores de los parámetros. En este caso, la hipótesis es que el valor de $\theta$, la proporción de perros sacrificados en Monico-2, es superior a 0.5 (50 %, Tabla 6). Los valores que se muestran en la Tabla 6 son inferencias resultantes de cálculos realizados utilizando la distribución posterior. El arqueólogo calculó la probabilidad de que $\theta$ sea mayor que 0.5 (valor superior a la izquierda en la tabla) y los valores de $\theta$ en los percentiles de probabilidad 5, 50 y 95. Recuerde, anteriormente, el arqueólogo junto con otros científicos propusieron que las marcas de corte deberían aparecer en al menos el 50 % (o 0.5) de los restos de perros en un sitio de Monico para considerar a los perros como «una importante contribución de alimentos». Sin embargo, la Tabla 6 muestra que el valor de $\theta$ solamente tiene un 10 % de probabilidad de ser mayor al 50 %. Por lo tanto, la inferencia de que los perros eran una parte sustancial de la dieta de Monico en Monico-2 no es muy probable. Por ejemplo, el arqueólogo piensa: «Si un meteorólogo me dijera que hoy hay un 10 % de probabilidad de lluvia, no llevaría paraguas». 

Es importante destacar que la incertidumbre en torno al valor de $\theta$ también puede expresarse como un intervalo de probabilidad. En el marco bayesiano, estos intervalos de probabilidad se conocen como los *intervalos de densidad de probabilidad más alta* (HPDI) y difieren de los IC de NHST. Una de las diferencias más importantes es que la interpretación del HPDI es mucho más sencilla. El HPDI es la probabilidad del parámetro dados los datos, mientras que, como describimos anteriormente, el IC no es una probabilidad sobre el valor de la estimación del parámetro. En el caso de $\theta$, a Figura 5 le dice al arqueólogo que existe mucha incertidumbre en torno al verdadero valor de $\theta$. Por ejemplo, la estimación de la mediana, o percentil 50, de $\theta$ es 0.38, lo que significa que, una vez que se incorpora la información previa disponible de la literatura y los datos de Monico-2, es muy probable que los ocupantes de Monico-2 incluyeran perros en su dieta el 38 % de las veces. Sin embargo, el HPDI del 90 % abarca de 0.23 a 0.53 (23 % a 53 %), lo que significa que, según nuestra información previa y los datos actuales, existe un 90 % de posibilidades de que θ se encuentre entre estos valores y solo un 10 % de posibilidades de que es mayor o menor que estos límites. Si bien la variación en $\theta$ alcanza más del 50 %, lo hace solo levemente y de nuevo es poco probable. Estos resultados significan que el arqueólogo no está muy seguro acerca de la propensión de los ocupantes a sacrificar perros (presuntamente) con fines dietéticos en Monico-2, especialmente considerando el pequeño tamaño de la muestra y el hecho de que los datos actuales de Monico-2 difieren bastante de los encontrados en otros sitios.

```{r table6, echo=FALSE, eval=TRUE}

table_6 <- dplyr::tibble(posterior_median, paste(posterior_hdi_90[1], "-", posterior_hdi_90[2], sep = ""), hypothesis_1_over50)

kb <- kable(table_6, digits = 2, col.names =c("Posterior Median", "90% HPDI", "P($\\theta$ > 0.5)"), caption = "Inferencias sobre $\\theta$ a partir de la distribución de probabilidad posterior")
kableExtra::kable_styling(kb, bootstrap_options = "hover", full_width = F)%>%
  kable_styling(latex_options = "HOLD_position")
```
